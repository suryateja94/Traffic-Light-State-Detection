{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traffic Signal State Detection\n",
    "This is a three stage process to detect the state of a traffic signal for auto-start/stop of cars on signals "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw\n",
    "from math import atan2, sqrt, pi, cos, sin\n",
    "from collections import defaultdict\n",
    "import random as rng"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Color Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def RedSignalIntensityBounds():\n",
    "    return ([4, 0, 200], [150, 80, 246])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def YellowSignalIntensityBounds():\n",
    "    return ([0, 160, 186], [46, 220, 255])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def GreenSignalIntensityBounds():\n",
    "    return ([0, 100, 0], [80, 230, 56])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ColorBounding(image,  color):\n",
    "    height, width, alp = image.shape\n",
    "    if color == \"Red\":\n",
    "        lower, upper = RedSignalIntensityBounds()\n",
    "    if color == \"Yellow\":\n",
    "        lower, upper = YellowSignalIntensityBounds()\n",
    "    if color == \"Green\":\n",
    "        lower, upper = GreenSignalIntensityBounds()\n",
    "    lower = np.array(lower, dtype = \"uint8\")\n",
    "    upper = np.array(upper, dtype = \"uint8\")\n",
    "    \n",
    "    mask = cv2.inRange(image, lower, upper)\n",
    "    output = cv2.bitwise_and(image, image, mask = mask)\n",
    "    cropped = []\n",
    "    x = 0\n",
    "    for i in output:\n",
    "        x = x + 1\n",
    "        y = 0\n",
    "        for j in i:\n",
    "            y = y+1\n",
    "            if j[0]!=0 and j[1]!=0 and j[2]!=0:\n",
    "                cropped.append([y,x])\n",
    "                #print(\"x at \"+str(x)+\" y at \"+str(y))\n",
    "    #print(len(cropped))\n",
    "    if len(cropped) != 0:\n",
    "        min_y = min(cropped, key = lambda x : x[1])\n",
    "        max_y = max(cropped, key = lambda x : x[1])\n",
    "        min_x = min(cropped, key = lambda x : x[0])\n",
    "        max_x = max(cropped, key = lambda x : x[0])\n",
    "        x_min_coordinate = min_x[0]\n",
    "        y_min_coordinate = min_y[1]\n",
    "        x_max_coordinate = max_x[0]\n",
    "        y_max_coordinate = max_y[1]\n",
    "        #print (min_x,min_y,max_x,max_y)\n",
    "        crop_img = image[y_min_coordinate-25:y_max_coordinate+25,x_min_coordinate-25:x_max_coordinate+25]\n",
    "        #print(crop_img)\n",
    "        cv2.imwrite(\"colorboundingoutput.jpg\",crop_img)\n",
    "        return (True, crop_img, x_min_coordinate, y_min_coordinate, x_max_coordinate, y_max_coordinate)\n",
    "    if len(cropped) == 0:\n",
    "        return (False, cropped, -1, -1, -1, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hough Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def GAUSS_BLUR(pixels, w, h):\n",
    "    kernel = (1/256) * np.array([[1,  4,  6,  4, 1],\n",
    "                                 [4, 16, 24, 16, 4],\n",
    "                                 [6, 24, 36, 24, 6], \n",
    "                                 [4, 16, 24, 16, 4],\n",
    "                                 [1,  4,  6,  4, 1]])\n",
    "\n",
    "    mid = len(kernel) // 2\n",
    "    share = lambda x, l, u: l if x < l else u if x > u else x\n",
    "    blurred = np.empty((w, h))\n",
    "    for x in range(w):\n",
    "        for y in range(h):\n",
    "            adder = 0\n",
    "            for a in range(len(kernel)):\n",
    "                for b in range(len(kernel)):\n",
    "                    xn = share(x + a - mid, 0, w - 1)\n",
    "                    yn = share(y + b - mid, 0, h - 1)\n",
    "                    adder += pixels[xn, yn] * kernel[a, b]\n",
    "            blurred[x, y] = int(adder)\n",
    "    return blurred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def to_GRAY(pixels, w, h):\n",
    "    gray = np.empty((w, h))\n",
    "    for x in range(w):\n",
    "        for y in range(h):\n",
    "            pixel = pixels[x, y]\n",
    "            gray[x, y] = (pixel[0] + pixel[1] + pixel[2]) / 3\n",
    "    return gray\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def CANNY(pixels, w, h):\n",
    "    gray = to_GRAY(pixels, w, h)\n",
    "    blur = GAUSS_BLUR(gray, w, h)\n",
    "    gradient, direction = GRADIENT(blur, w, h)\n",
    "    Filter1(gradient, direction, w, h)\n",
    "    res = Filter2(gradient, w, h, 20, 25)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def GRADIENT(pixels, w, h):\n",
    "    direction = np.zeros((w, h))\n",
    "    gradient = np.zeros((w, h))\n",
    "    for x in range(w):\n",
    "        for y in range(h):\n",
    "            if 0 < x < w - 1 and 0 < y < h - 1:\n",
    "                magx = pixels[x + 1, y] - pixels[x - 1, y]\n",
    "                magy = pixels[x, y + 1] - pixels[x, y - 1]\n",
    "                gradient[x, y] = sqrt(magx**2 + magy**2)\n",
    "                direction[x, y] = atan2(magy, magx)\n",
    "    return gradient, direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Filter1(gradient, direction, w, h):\n",
    "    for x in range(1, w - 1):\n",
    "        for y in range(1, h - 1):\n",
    "            if direction[x, y] >= 0:\n",
    "                angle = direction[x, y]\n",
    "            else:\n",
    "                angle = direction[x, y] + pi\n",
    "            rangle = round(angle / (pi / 4))\n",
    "            mag = gradient[x, y]\n",
    "            if ((rangle == 0 or rangle == 4) and (gradient[x - 1, y] > mag or gradient[x + 1, y] > mag)\n",
    "                    or (rangle == 1 and (gradient[x - 1, y - 1] > mag or gradient[x + 1, y + 1] > mag))\n",
    "                    or (rangle == 2 and (gradient[x, y - 1] > mag or gradient[x, y + 1] > mag))\n",
    "                    or (rangle == 3 and (gradient[x + 1, y - 1] > mag or gradient[x - 1, y + 1] > mag))):\n",
    "                gradient[x, y] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Filter2(gradient, w, h, low, high):\n",
    "    holder1 = set()\n",
    "    for x in range(w):\n",
    "        for y in range(h):\n",
    "            if gradient[x, y] > high:\n",
    "                holder1.add((x, y))\n",
    "    copy = holder1\n",
    "    while copy:\n",
    "        holder2 = set()\n",
    "        for x, y in copy:\n",
    "            for a, b in ((-1, -1), (-1, 0), (-1, 1), (0, -1), (0, 1), (1, -1), (1, 0), (1, 1)):\n",
    "                if gradient[x + a, y + b] > low and (x+a, y+b) not in holder1:\n",
    "                    holder2.add((x+a, y+b))\n",
    "        holder1.update(holder2)\n",
    "        copy = holder2\n",
    "\n",
    "    return list(holder1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def HOUGH_T(tempImage, rmin, rmax, steps, th):\n",
    "    image = Image.open(tempImage)\n",
    "    coord = []\n",
    "    for r in range(rmin, rmax + 1):\n",
    "        for t in range(steps):\n",
    "            coord.append((r, int(r * cos(2 * pi * t / steps)), int(r * sin(2 * pi * t / steps))))\n",
    "\n",
    "    acc = defaultdict(int)\n",
    "    pixels = image.load()\n",
    "    w = image.width\n",
    "    h = image.height\n",
    "    cannyOutput = CANNY(pixels, w, h)\n",
    "    for x, y in cannyOutput:\n",
    "        for r, dx, dy in coord:\n",
    "            a = x - dx\n",
    "            b = y - dy\n",
    "            acc[(a, b, r)] += 1\n",
    "\n",
    "    circles = []\n",
    "    for k, v in sorted(acc.items(), key=lambda i: -i[1]):\n",
    "        x, y, r = k\n",
    "        if v / steps >= th and all((x - xc) ** 2 + (y - yc) ** 2 > rc ** 2 for xc, yc, rc in circles):\n",
    "            #print(v / steps, x, y, r)\n",
    "            circles.append((x, y, r))\n",
    "    \n",
    "    output_image = Image.new(\"RGB\", image.size)\n",
    "    output_image.paste(image)\n",
    "    draw_result = ImageDraw.Draw(output_image)\n",
    "    for x, y, r in circles:\n",
    "        draw_result.ellipse((x-r, y-r, x+r, y+r), outline=(255,0,0,0))\n",
    "\n",
    "    # Save output image\n",
    "    output_image.save(\"result.jpg\")\n",
    "    \n",
    "    if len(circles) > 0:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def TrafficLightObjectDetection(img, xminCir, xmaxCir, yminCir, ymaxCir):\n",
    "    bounded_circle = False\n",
    "    bounded_Rectangle = False\n",
    "    edges = cv2.Canny(img,100,200)\n",
    "    contours,h = cv2.findContours(edges,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contours = sorted(contours, key=cv2.contourArea, reverse=True)[:3]\n",
    "    contours_poly = [None]*len(contours)\n",
    "    boundRect = [None]*len(contours)\n",
    "    centers = [None]*len(contours)\n",
    "    radius = [None]*len(contours)\n",
    "    for i, c in enumerate(contours):\n",
    "        per = cv2.arcLength(c,True)\n",
    "        app = cv2.approxPolyDP(c,0.05*per, True)\n",
    "        contours_poly[i] = app\n",
    "        if len(app)>3:\n",
    "            boundRect[i] = cv2.boundingRect(contours_poly[i])\n",
    "            centers[i], radius[i] = cv2.minEnclosingCircle(contours_poly[i])\n",
    "\n",
    "    drawing = np.zeros((edges.shape[0], edges.shape[1], 3), dtype=np.uint8)\n",
    "    # Draw polygonal contour + bonding rects + circles\n",
    "    for i in range(len(contours)):\n",
    "        color = (rng.randint(0,256), rng.randint(0,256), rng.randint(0,256))\n",
    "        if len(contours_poly[i]) >3:\n",
    "            cv2.drawContours(edges, contours_poly, i, color)\n",
    "            cv2.rectangle(edges, (int(boundRect[i][0]), int(boundRect[i][1])), \\\n",
    "                          (int(boundRect[i][0]+boundRect[i][2]), int(boundRect[i][1]+boundRect[i][3])), color, 2)\n",
    "            cv2.circle(edges, (int(centers[i][0]), int(centers[i][1])), int(radius[i]), color, 2)\n",
    "            #print(int(boundRect[i][0]), int(boundRect[i][1]),int(boundRect[i][0]+boundRect[i][2]), int(boundRect[i][1]+boundRect[i][3]))\n",
    "            xminRect = int(boundRect[i][0])-10\n",
    "            xmaxRect = int(boundRect[i][0]+boundRect[i][2])+10\n",
    "            yminRect = int(boundRect[i][1])\n",
    "            ymaxRect = int(boundRect[i][1]+boundRect[i][3])\n",
    "            #print(\"YE\")\n",
    "            #print(xminCir)\n",
    "            #print(xmaxCir)\n",
    "            #print(yminCir)\n",
    "            #print(ymaxCir)\n",
    "            #print(\"YESS\")\n",
    "            #print(xminRect)\n",
    "            #print(xmaxRect)\n",
    "            #print(yminRect)\n",
    "            #print(ymaxRect)\n",
    "            #print(\"CIRCRC\")\n",
    "            #print((int(centers[i][0])-int(radius[i])))\n",
    "            #print((int(centers[i][0])+int(radius[i])))\n",
    "            #print((int(centers[i][1])-int(radius[i])))\n",
    "            #print((int(centers[i][1])+int(radius[i])))\n",
    "            if ((xminCir + xmaxCir)/2) >= xminRect and ((xminCir + xmaxCir)/2) <= xmaxRect and ((yminCir + ymaxCir)/2) <= ymaxRect and ((yminCir + ymaxCir)/2) >= yminRect:\n",
    "                bounded_Rectangle = True\n",
    "                #print(\"MMMMMMMMMMM.\")\n",
    "            if ((xminCir + xmaxCir)/2) >= (int(centers[i][0])-int(radius[i])) and ((xminCir + xmaxCir)/2) <= (int(centers[i][0])+int(radius[i])) and ((yminCir + ymaxCir)/2) >= (int(centers[i][1])-int(radius[i])) and ((yminCir + ymaxCir)/2) <= (int(centers[i][1])+int(radius[i])):\n",
    "                bounded_circle = True\n",
    "                #print(\"LOLOLOLOLO\")\n",
    "    cv2.imwrite(\"houghoutput.jpg\", edges)\n",
    "    if bounded_circle or bounded_Rectangle:\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Driver Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def TrafficSignalStateDetection(image):\n",
    "    trafficState = \"None\"\n",
    "    isRed, crop_img, xmin, ymin, xmax, ymax = ColorBounding(image, \"Red\")\n",
    "    #print(isRed)\n",
    "    if isRed:\n",
    "        trafficState = \"Red\"\n",
    "    if trafficState == \"None\" or trafficState == \"Red\":\n",
    "        isYellow, crop_img_yellow, xmin_yellow, ymin_yellow, xmax_yellow , ymax_yellow = ColorBounding(image, \"Yellow\")\n",
    "        #print(isYellow)\n",
    "        if isYellow:\n",
    "            trafficState = \"Yellow\"\n",
    "            crop_img = crop_img_yellow\n",
    "            xmin = xmin_yellow\n",
    "            ymin = ymin_yellow\n",
    "            xmax = xmax_yellow\n",
    "            ymax = ymax_yellow\n",
    "    if trafficState == \"None\":\n",
    "        isGreen, crop_img, xmin, ymin, xmax, ymax = ColorBounding(image, \"Green\")\n",
    "        #print(isGreen)\n",
    "        if isGreen:\n",
    "            trafficState = \"Green\"\n",
    "    if trafficState == \"None\":\n",
    "        print(\"No Traffic Signals Detected!\")\n",
    "    if trafficState != \"None\":\n",
    "        houghoutput = HOUGH_T(\"colorboundingoutput.jpg\", 10, 100, 120, 0.3)\n",
    "        if houghoutput:\n",
    "            finalOutput = TrafficLightObjectDetection(image, xmin, xmax, ymin, ymax)\n",
    "            #print(finalOutput)\n",
    "            if finalOutput:\n",
    "                print(\"Current traffic Signal state: \" + trafficState)\n",
    "                return trafficState\n",
    "            else:\n",
    "                print(\"Circle with color \" + trafficState + \" detected but not a traffic signal\")\n",
    "        else:\n",
    "            print(\"No Traffic Signals Detected but \" + trafficState + \" color detected!\")\n",
    "    return \"None\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Signal Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current traffic Signal state: Red\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Red'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = cv2.imread('red.jpg')\n",
    "TrafficSignalStateDetection(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Video Signal Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current traffic Signal state: Red\n",
      "Red\n",
      "Current traffic Signal state: Red\n",
      "Red\n",
      "Current traffic Signal state: Red\n",
      "Red\n",
      "Current traffic Signal state: Red\n",
      "Red\n",
      "Current traffic Signal state: Yellow\n",
      "Yellow\n",
      "Current traffic Signal state: Yellow\n",
      "Yellow\n",
      "Current traffic Signal state: Green\n",
      "Green\n"
     ]
    }
   ],
   "source": [
    "\n",
    "vidcap = cv2.VideoCapture('four.mp4')\n",
    "success,image = vidcap.read()\n",
    "count = 0\n",
    "font                   = cv2.FONT_HERSHEY_SIMPLEX\n",
    "upperLeftCornerOfText = (100,100)\n",
    "fontScale              = 1\n",
    "fontColor              = (255,255,255)\n",
    "lineType               = 2\n",
    "while success:\n",
    "  #TrafficSignalStateDetection(image)\n",
    "  vidcap.set(cv2.CAP_PROP_POS_MSEC, (count*1000))\n",
    "  #print('Read a new frame: ', success)\n",
    "  \n",
    "  state = TrafficSignalStateDetection(image)\n",
    "  print(state)\n",
    "  cv2.putText(image,'State: '+state, upperLeftCornerOfText, font, fontScale, fontColor, lineType)\n",
    "  cv2.imwrite(\"frames/frame\"+str(count)+\".jpg\", image)# save frame as JPEG file\n",
    "  \n",
    "  success,image = vidcap.read()\n",
    "  count += 1\n",
    "#print(count)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stitching all frames together for a Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "files = [f for f in os.listdir(\"frames\")]\n",
    "files.sort(key = lambda x: int(x[5:-4]))\n",
    "image_array = []\n",
    "for i in range(len(files)):\n",
    "    img = cv2.imread(\"frames/\"+files[i])\n",
    "    size = (img.shape[1], img.shape[0])\n",
    "    img = cv2.resize(img, size)\n",
    "    image_array.append(img)\n",
    "fou = cv2.VideoWriter_fourcc('D','I','V','X')\n",
    "out = cv2.VideoWriter(\"video/video.mp4\", fou, 1, size)\n",
    "for i in range(len(image_array)):\n",
    "    out.write(image_array[i])\n",
    "out.release()\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
